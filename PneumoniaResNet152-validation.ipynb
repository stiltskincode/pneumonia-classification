{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpjNZnfKOZ1lQOLmEYGGti"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dRfLB8wAs0l"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/colab/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "qGrPSwqCGYOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c rsna-pneumonia-detection-challenge"
      ],
      "metadata": {
        "id": "70guBixEGmjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip rsna-pneumonia-detection-challenge.zip -d /content/rsna_pneumonia"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wCrJS97gG3fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydicom"
      ],
      "metadata": {
        "id": "RAWwzbBPH21B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import pydicom\n",
        "import cv2\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "qO_vQV92HoGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = 'rsna_pneumonia/'\n",
        "SAVE_PATH = Path(DATA_PATH + 'processed')\n",
        "ROOT_PATH = Path(DATA_PATH + 'stage_2_train_images')"
      ],
      "metadata": {
        "id": "vlwZJ1hrFWKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = pd.read_csv(DATA_PATH + 'stage_2_train_labels.csv')\n",
        "labels = labels.drop_duplicates('patientId')"
      ],
      "metadata": {
        "id": "xbnkFoS-IKZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sums, sums_squared = 0, 0\n",
        "for c, patient_id in enumerate(tqdm(labels.patientId)):\n",
        "  patient_id = labels.patientId.iloc[c]\n",
        "  dcm_path = ROOT_PATH/patient_id\n",
        "  dcm_path = dcm_path.with_suffix(\".dcm\")\n",
        "  dcm = pydicom.dcmread(dcm_path).pixel_array / 255\n",
        "\n",
        "  dcm_array = cv2.resize(dcm, (224, 224)).astype(np.float16)\n",
        "\n",
        "  label = labels.Target.iloc[c]\n",
        "\n",
        "  train_or_val = \"train\" if c < 24000 else \"val\"\n",
        "\n",
        "  current_save_path = SAVE_PATH/train_or_val/str(label)\n",
        "  current_save_path.mkdir(parents=True, exist_ok=True)\n",
        "  np.save(current_save_path/patient_id, dcm_array)\n",
        "\n",
        "  normalizer = 224*224\n",
        "  if train_or_val == \"train\":\n",
        "    sums += np.sum(dcm_array) / normalizer\n",
        "    sums_squared += (dcm_array ** 2).sum() / normalizer"
      ],
      "metadata": {
        "id": "O01c_I_PHhuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightning"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PheC0SrZEyRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import os\n",
        "from torchvision import transforms\n",
        "import glob\n",
        "import torchmetrics"
      ],
      "metadata": {
        "id": "BJPczxpOFPzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_file(path):\n",
        "    return np.load(path).astype(float)"
      ],
      "metadata": {
        "id": "9rh_S7wXFj40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(0.49, 0.248)\n",
        "])"
      ],
      "metadata": {
        "id": "ma6D0wb8Fvtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = torchvision.datasets.DatasetFolder(\n",
        "    root=os.path.join(SAVE_PATH, 'val'),\n",
        "    loader=load_file,\n",
        "    extensions=('npy',),\n",
        "    transform=val_transforms\n",
        ")"
      ],
      "metadata": {
        "id": "tmRWDcb5FLr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/stiltskincode/pneumonia-classification/refs/heads/main/models/pneumonia_resnet152.py"
      ],
      "metadata": {
        "id": "q_YTYPbZDs--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DRIVE_PATH = '/content/drive/MyDrive/colab'"
      ],
      "metadata": {
        "id": "Anx6lNqHKmY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoints_dir = os.path.join(DRIVE_PATH, \"logs/lightning_logs/version_1/checkpoints/\")"
      ],
      "metadata": {
        "id": "zYz4zgUHKf9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pneumonia_resnet152 import PneumoniaResNet152"
      ],
      "metadata": {
        "id": "HfSidGXtD6vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_latest_checkpoint(checkpoints_dir):\n",
        "    checkpoint_files = glob.glob(os.path.join(checkpoints_dir, '*.ckpt'))\n",
        "\n",
        "    if checkpoint_files:\n",
        "        latest_checkpoint = max(checkpoint_files, key=os.path.getmtime)\n",
        "        print(f\"Resuming from checkpoint: {latest_checkpoint}\")\n",
        "        return latest_checkpoint\n",
        "    else:\n",
        "        print(\"No checkpoint found. Starting training from scratch.\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "WwzVjiKyKzXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latest_checkpoint = get_latest_checkpoint(checkpoints_dir)"
      ],
      "metadata": {
        "id": "m6IBYDKuKWkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "AqfdeE4mK_vV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PneumoniaResNet152.load_from_checkpoint(checkpoint_path=latest_checkpoint)\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WL-WcpXJLElN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "labels = []\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data, label, in tqdm(val_dataset):\n",
        "        data = data.to(device).float().unsqueeze(0)\n",
        "        pred = torch.sigmoid(model(data)[0].cpu())\n",
        "        pred_binary = (pred > 0.5).int()  # Threshold at 0.5 to get binary output\n",
        "        preds.append(pred_binary)\n",
        "        labels.append(label)\n",
        "preds = torch.tensor(preds)\n",
        "labels = torch.tensor(labels).int()\n",
        "\n",
        "\n",
        "acc = torchmetrics.Accuracy(task=\"binary\")(preds, labels)\n",
        "precision = torchmetrics.Precision(task=\"binary\")(preds, labels)\n",
        "recall = torchmetrics.Recall(task=\"binary\")(preds, labels)\n",
        "cm = torchmetrics.ConfusionMatrix(task=\"binary\")(preds, labels)\n",
        "\n",
        "print(f\"Val Acc {acc}\")\n",
        "print(f\"Val Precision {precision}\")\n",
        "print(f\"Val Recall {recall}\")\n",
        "print(f\"Confucion Matrix {cm}\")"
      ],
      "metadata": {
        "id": "XGkNNCujLWAk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}